{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "29_CNN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16EISBleGU5d1tNrm0uXLErrxKU4q3bOM",
      "authorship_tag": "ABX9TyMo2rj5k82nGY7gIlxTHN/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mochismo/LearnPython/blob/main/29_CNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the dataset "
      ],
      "metadata": {
        "id": "yKaSNnQ_LgBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 696,
      "metadata": {
        "id": "LifQSJzD7-jV"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Evaluation Index\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download mnist dataset \n",
        "from keras.datasets import mnist\n",
        "(X, y), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "9XZ7eftNL-_I"
      },
      "execution_count": 697,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data\n",
        "print(X.shape)\n",
        "print(X_test.shape)\n",
        "print(X[0].dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwaov8n7MZxN",
        "outputId": "b8de65d1-5f69-48b7-d3bc-09b7a02400a0"
      },
      "execution_count": 698,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Type conversion, normalization\n",
        "X = X.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X /= 255\n",
        "X_test /= 255\n",
        "print(X.max())\n",
        "print(X.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfLkV_NRNnVP",
        "outputId": "8e530fcc-d2fd-41d1-f588-fa6b8fd00cfc"
      },
      "execution_count": 699,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding of correct label value\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
        "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y.shape)\n",
        "print(y_one_hot.shape)\n",
        "print(y_one_hot.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muM3I4VmOQS-",
        "outputId": "74adc280-281b-42fe-a8c2-21a1ea72e3dc"
      },
      "execution_count": 700,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training data and validation data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_one_hot, test_size = 0.2)\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PlHDvHHQMDY",
        "outputId": "1aaafc49-bf82-4f96-be25-a69487a9f1eb"
      },
      "execution_count": 701,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 28, 28)\n",
            "(12000, 28, 28)\n",
            "(48000, 10)\n",
            "(12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully connected layers"
      ],
      "metadata": {
        "id": "Q27aHAKARAM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "  def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
        "    self.n_nodes1 = n_nodes1\n",
        "    self.n_nodes2 = n_nodes2\n",
        "    self.initializer = initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.activation = activation\n",
        "   \n",
        "    # Initialize.\n",
        "    # Use the initializer method to initialize self.W and self.B\n",
        "    self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "    self.B = self.initializer.B(self.n_nodes2)\n",
        "\n",
        "    \n",
        "  def forward(self, X):\n",
        "      self.X = X\n",
        "      self.A = np.dot(self.X, self.W) + self.B\n",
        "      return self.activation.forward(self.A) \n",
        "\n",
        "  def backward(self, dZ):\n",
        "      dA = self.activation.backward(dZ)\n",
        "      self.dB = np.mean(dA, axis=0)\n",
        "      self.dW = np.dot(self.X.T, dA)/len(self.X)\n",
        "      dZ = np.dot(dA, self.W.T)\n",
        "\n",
        "      # update \n",
        "      self = self.optimizer.update(self)\n",
        "      return dZ"
      ],
      "metadata": {
        "id": "m3yoTd4FQ8VD"
      },
      "execution_count": 702,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization"
      ],
      "metadata": {
        "id": "412nCmZOYJO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializerConv2d:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "    def W(self, F, C,FH, FW):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        return self.sigma* np.random.randn(F, C,FH, FW)\n",
        "        \n",
        "    def B(self,F):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        return np.zeros(F)      "
      ],
      "metadata": {
        "id": "91ikcRHivG4f"
      },
      "execution_count": 703,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s6-FlqhBZ0Tz"
      },
      "execution_count": 703,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        return self.sigma* np.random.randn(n_nodes1, n_nodes2)\n",
        "        \n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        B : bias\n",
        "        \"\"\"\n",
        "        return np.zeros(n_nodes2)"
      ],
      "metadata": {
        "id": "kyx9iYSRZ01G"
      },
      "execution_count": 704,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    \n",
        "    return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2 / n_nodes1)   \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    \n",
        "    return np.zeros(n_nodes2)    "
      ],
      "metadata": {
        "id": "VcurYrE-BFL-"
      },
      "execution_count": 705,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization"
      ],
      "metadata": {
        "id": "oyijqkQ7bz_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MCawigsfb4GP"
      },
      "execution_count": 705,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    Stochastic gradient descent\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : Learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr* layer.dW\n",
        "      layer.B -= self.lr* layer.dB\n",
        "      \n",
        "      return layer\n",
        "    \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "uB_cgLY5wSQz"
      },
      "execution_count": 706,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr\n",
        "    self.hW = 0\n",
        "    self.hB = 0\n",
        "\n",
        "  def update(self, layer):\n",
        "    layer.hW += layer.dW * layer.dW\n",
        "    layer.hB = layer.dB * layer.dB\n",
        "\n",
        "    \n",
        "    layer.W -=self.lr * layer.dW / (np.sqrt(layer.HW) + 1e-7)\n",
        "    layer.B -=self.lr * layer.dB / (np.sqrt(layer.HB) + 1e-7)\n",
        "    return layer  "
      ],
      "metadata": {
        "id": "l5DsMeljCl9w"
      },
      "execution_count": 707,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Function "
      ],
      "metadata": {
        "id": "laGg9B-De-uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "emeDYC6OfEhO"
      },
      "execution_count": 707,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, A): \n",
        "    self.A = A\n",
        "    return np.maximum(self.A, 0)\n",
        "      \n",
        "  def backward(self, dZ):\n",
        "    return np.where(self.A > 0, dZ, 0)"
      ],
      "metadata": {
        "id": "olezBeBT7KOG"
      },
      "execution_count": 708,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax():\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, A):\n",
        "    return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)), axis=1, keepdims=True)\n",
        "      \n",
        "  def backward(self, dZ):\n",
        "    \n",
        "    return dZ\n"
      ],
      "metadata": {
        "id": "8iydHnvO2KgY"
      },
      "execution_count": 709,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MiniBatch"
      ],
      "metadata": {
        "id": "qZofQSScpl-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "  def __init__(self, X, y, batch_size = 20, seed=None):\n",
        "    self.batch_size = batch_size\n",
        "    np.random.seed(seed)\n",
        "    shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "    self._X = X[shuffle_index]\n",
        "    self._y = y[shuffle_index]\n",
        "    self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._stop\n",
        "\n",
        "  def __getitem__(self, item): \n",
        "    p0 = item*self.batch_size\n",
        "    p1 = item*self.batch_size + self.batch_size\n",
        "    return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "  def __iter__(self): \n",
        "    self._counter = 0\n",
        "    return self \n",
        "\n",
        "  def __next__(self):\n",
        "    if self._counter >= self._stop:\n",
        "      raise StopIteration()\n",
        "    p0 = self._counter*self.batch_size\n",
        "    p1 = self._counter*self.batch_size + self.batch_size \n",
        "    self._counter += 1\n",
        "    return self._X[p0:p1], self._y[p0:p1] "
      ],
      "metadata": {
        "id": "tdY6SXGfGc_h"
      },
      "execution_count": 710,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 【Problem 1】Creating a 2-D convolutional layer"
      ],
      "metadata": {
        "id": "3xL0hOZfkJxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fW6VR-hykPo_"
      },
      "execution_count": 710,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConv2d():\n",
        "    \n",
        "    def __init__(self, F, C, FH, FW, P, S, initializer=None, optimizer=None, activation=None):\n",
        "\n",
        "      self.P = P\n",
        "      self.S = S\n",
        "      self.initializer = initializer\n",
        "      self.optimizer = optimizer\n",
        "      self.activation = activation\n",
        "\n",
        "      # Initialize.\n",
        "      # Use initializer method to initialize self.W and self.B\n",
        "      self.W =self.initializer.W(F, C, FH, FW)\n",
        "      self.B = self.initializer.B(F)\n",
        "\n",
        "    def output_shape2d(self, H, W, PH, PW, FH, FW, SH, SW):\n",
        "      OH = (H + 2*PH - FH)/SH +1\n",
        "      OW = (W + 2*PW - FW)/SW +1\n",
        "      return int(OH), int(OW)\n",
        "\n",
        "    def forward(self, X):\n",
        "      self.X = X\n",
        "      N, C, H, W = self.X.shape\n",
        "      F, C, FH, FW = self.W.shape\n",
        "\n",
        "      OH, OW = self.output_shape2d(H, W, self.P, FH, FW, self.S, self.S)\n",
        "\n",
        "      self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "\n",
        "      A = np.zeros((N,F,OH,OW))  \n",
        "      self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P, self.P), (self.P, self.P)))\n",
        "\n",
        "      #Batch\n",
        "      for n in range(N):\n",
        "        #output channels\n",
        "        for ch in range(F):\n",
        "          #vertical slide\n",
        "          for row in range(0,H,self.S):\n",
        "            # horizontal slide\n",
        "            for col in range(0,W,self.S):\n",
        "              A[n,ch,row,col] = np.sum(self.X_pad[n,:, row:row + FH, col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
        "      return self.activation.forward(A)\n",
        "\n",
        "    def backward(self, dZ):\n",
        "      dA = self.activation.backward(dZ)\n",
        "      N, C, H, W, F, FH, FW, OH, OW = self.params\n",
        "      \n",
        "      dZ = np.zeros(self.X_pad.shape)\n",
        "      self.dW = np.zeros(self.W.shape) \n",
        "      self.dB = np.zeros(self.B.shape)\n",
        "\n",
        "      #dZ\n",
        "      #Batch\n",
        "      for n in range(N):\n",
        "        # Output channels\n",
        "        for ch in range(F):\n",
        "          # Vertical slide\n",
        "          for row in range(0,H,self.S):\n",
        "            # Horizontal Slide\n",
        "            for col in range(0,W,self.S):\n",
        "              dZ[n,:,row:row+FH, col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "      dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
        "      dl_cols = range(self.P),range(w+self.P,W+2*self.P,1)\n",
        "\n",
        "      dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "      dZ = np.delete(dZ,dl_cols,axis=2)\n",
        "\n",
        "      #dW\n",
        "      #Batch\n",
        "      for n in range(N):\n",
        "        # Output channels\n",
        "        for ch in range(F):\n",
        "          # Vertical slide\n",
        "          for row in range(0,H):\n",
        "            # Horizontal Slide\n",
        "            for col in range(0,W):\n",
        "              self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "      #dB\n",
        "      #Output channels\n",
        "      for ch in range(F):\n",
        "        self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "      #update\n",
        "      self = self.optimizer.update(self)  \n",
        "      return dZ      "
      ],
      "metadata": {
        "id": "zt97TXnAlhhE"
      },
      "execution_count": 711,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2 & 3 - Experiments with 2D convolutional layers on small arrays and output size after 2-dimensional convolution"
      ],
      "metadata": {
        "id": "jqIW7dPZlQAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_shape2d(IH=5,IW=5,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1):\n",
        "  OH = (IH + 2*PH -FH)/SH +1\n",
        "  OW = (IW + 2*PW -FW)/SW +1\n",
        "  return int(OH), int(OW)"
      ],
      "metadata": {
        "id": "TiR3at_1k1XC"
      },
      "execution_count": 712,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_shape2d(IH=6,IW=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcj7M6IBvyLl",
        "outputId": "06b9e353-9814-4cd1-b721-0de32e594490"
      },
      "execution_count": 713,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with 2D convolution"
      ],
      "metadata": {
        "id": "YScpfVu7vxsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N,C,H,W = (5,1,28,28)\n",
        "F,C,FH,FW = (4,1,3,3)\n",
        "\n",
        "S = 1 #FIXED FOR NOW\n",
        "P = 1\n",
        "\n",
        "OH,OW = output_shape2d(H,W,P,P,FH,FW,S,S)\n",
        "\n",
        "A = np.zeros([N,F,OH,OW])\n",
        "X_sample = X[0:N].reshape(N,C,H,W)\n",
        "X_pad = np.pad(X_sample,((0,0),(0,0),(P,P),(P,P)))\n",
        "w = np.ones([F,C,FH,FW])\n",
        "B = np.ones(F)\n",
        "\n",
        "#Forward\n",
        "#Batch\n",
        "for n in range(N):\n",
        "  # Output channels\n",
        "  for ch in range(F):\n",
        "    # Vertical slide\n",
        "    for row in range(0,H,S):\n",
        "      # Horizontal Slide\n",
        "      for col in range(0,W,S):\n",
        "        A[n,ch,row,col] = np.sum(X_pad[n,:,row:row+FH,col:col+FW]*w[ch,:,:,:]) +B[ch]\n",
        "print('A.shape:', A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhERYXQfw0v6",
        "outputId": "b889f500-a8bf-47cf-f6b0-4cb531b49592"
      },
      "execution_count": 714,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A.shape: (5, 4, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#backward\n",
        "dA = np.ones(A.shape)\n",
        "      \n",
        "dZ = np.zeros(X_pad.shape)\n",
        "dW = np.zeros(w.shape) \n",
        "dB = np.zeros(B.shape)\n",
        "\n",
        "#dZ\n",
        "#Batch\n",
        "for n in range(N):\n",
        "  # Output channels\n",
        "  for ch in range(F):\n",
        "    # Vertical slide\n",
        "    for row in range(0,H,S):\n",
        "      # Horizontal Slide\n",
        "      for col in range(0,W,S):\n",
        "        dZ[n,:,row:row+FH, col:col+FW] += dA[n,ch,row,col]*w[ch,:,:,:]\n",
        "dl_rows = range(P),range(H+P,H+2*P,1)\n",
        "dl_cols = range(P),range(W+P,W+2*P,1)\n",
        "\n",
        "dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "\n",
        "#dW\n",
        "#Batch\n",
        "for n in range(N):\n",
        "  # Output channels\n",
        "  for ch in range(F):\n",
        "    # Vertical slide\n",
        "    for row in range(0,H):\n",
        "      # Horizontal Slide\n",
        "      for col in range(0,W):\n",
        "        dW[ch,:,:,:] += dA[n,ch,row,col]*X_pad[n,:,row:row+FH,col:col+FW]\n",
        "#dB\n",
        "#Output channels\n",
        "for ch in range(F):\n",
        "  dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "\n",
        "print('dZ.shape:',dZ.shape)     \n",
        "print('dW.shape:',dW.shape)\n",
        "print('dB.shape:',dB.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmUotApa3bpC",
        "outputId": "13b2cbfe-5012-4366-da6f-4e61dae858f9"
      },
      "execution_count": 715,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dZ.shape: (5, 1, 28, 28)\n",
            "dW.shape: (4, 1, 3, 3)\n",
            "dB.shape: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4 - Creating a maximum pooling layer"
      ],
      "metadata": {
        "id": "8JecAyev7-CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2D():\n",
        "  def __init__(self, P):\n",
        "    self.P = P\n",
        "    self.PA = None\n",
        "    self.Pindex = None\n",
        "  def forward(self,A):\n",
        "    N,F,OH,OW = A.shape\n",
        "    PS = self.P\n",
        "    PH,PW = int(OH/PS),int(OW/PS)\n",
        "\n",
        "    self.params = N,F,OH,OW,PS,PH,PW\n",
        "\n",
        "    #pooling filter\n",
        "    self.PA = np.zeros([N,F,PH,PW])\n",
        "    self.Pindex = np.zeros([N,F,PH,PW])\n",
        "\n",
        "    for n in range(N):\n",
        "      # Output channels\n",
        "      for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(PH):\n",
        "          # Horizontal Slide\n",
        "          for col in range(PW):\n",
        "            self.PA[n,ch,row,col] = np.max(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "            self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "    return self.PA\n",
        "\n",
        "  def backward(self, dA):\n",
        "    N, F, OH, OW, PS, PH, PW = self.params\n",
        "    dP = np.zeros([N,F,OH,OW])\n",
        "    \n",
        "    for n in range(N):\n",
        "      # Output channels\n",
        "      for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(PH):\n",
        "          # Horizontal Slide\n",
        "          for col in range(PW):\n",
        "            idx = self.Pindex[n,ch,row,col]\n",
        "            tmp = np.zeros((PS*PS))\n",
        "            for i in range((PS*PS)):\n",
        "              if i == idx:\n",
        "                tmp[i] = dA[n,ch,row,col]\n",
        "              else:\n",
        "                tmp[i] = 0\n",
        "            dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "    return dP"
      ],
      "metadata": {
        "id": "ijOLO75m63v1"
      },
      "execution_count": 716,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c3sXjspDos5",
        "outputId": "4229ac51-1ba3-4492-f399-414075f3f25f"
      },
      "execution_count": 717,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[5 1 2 5 5 5]\n",
            "   [4 5 6 7 6 6]\n",
            "   [2 3 5 4 2 7]\n",
            "   [7 2 4 2 2 8]\n",
            "   [6 5 2 0 8 1]\n",
            "   [3 2 1 7 5 0]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling = MaxPool2D(P=2)\n",
        "A = Pooling.forward(X)\n",
        "print(A.shape)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5EyHNlVIS61",
        "outputId": "9bd49beb-04bf-493d-c002-0545064ac3f6"
      },
      "execution_count": 718,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 3, 3)\n",
            "[[[[5. 7. 6.]\n",
            "   [7. 5. 8.]\n",
            "   [6. 7. 8.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling.Pindex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lbathxCIyYl",
        "outputId": "c2d1af34-4312-4916-c5bc-ede475796919"
      },
      "execution_count": 719,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0., 3., 2.],\n",
              "         [2., 0., 3.],\n",
              "         [0., 3., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 719
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
        "print(dA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB8657OCI6AQ",
        "outputId": "7ea68f1f-00f1-43a0-f2dd-93d6af17c80d"
      },
      "execution_count": 720,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[3 6 2]\n",
            "   [7 6 2]\n",
            "   [5 5 7]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dZ = Pooling.backward(dA)\n",
        "\n",
        "print(dZ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbFUmVesJGTa",
        "outputId": "543edc96-a5fd-4806-e44b-fa04ae86f5c1"
      },
      "execution_count": 721,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[3. 0. 0. 0. 0. 0.]\n",
            "   [0. 0. 0. 6. 2. 0.]\n",
            "   [0. 0. 6. 0. 0. 0.]\n",
            "   [7. 0. 0. 0. 0. 2.]\n",
            "   [5. 0. 0. 0. 7. 0.]\n",
            "   [0. 0. 0. 5. 0. 0.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5 - (Advanced) Creating Average Pooling"
      ],
      "metadata": {
        "id": "oRHqPHvEOZkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AveragePool2D():\n",
        "  def __init__(self, P):\n",
        "    self.P = P\n",
        "    self.PA = None\n",
        "    self.Pindex = None\n",
        "  def forward(self,A):\n",
        "    N,F,OH,OW = A.shape\n",
        "    PS = self.P\n",
        "    PH,PW = int(OH/PS),int(OW/PS)\n",
        "\n",
        "    self.params = N,F,OH,OW,PS,PH,PW\n",
        "\n",
        "    #pooling filter\n",
        "    self.PA = np.zeros([N,F,PH,PW])\n",
        "\n",
        "    for n in range(N):\n",
        "      # Output channels\n",
        "      for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(PH):\n",
        "          # Horizontal Slide\n",
        "          for col in range(PW):\n",
        "            self.PA[n,ch,row,col] = np.mean(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "    return self.PA\n",
        "\n",
        "  def backward(self, dA):\n",
        "    N, F, OH, OW, PS, PH, PW = self.params\n",
        "    dP = np.zeros([N,F,OH,OW])\n",
        "    \n",
        "    for n in range(N):\n",
        "      # Output channels\n",
        "      for ch in range(F):\n",
        "        # Vertical slide\n",
        "        for row in range(PH):\n",
        "          # Horizontal Slide\n",
        "          for col in range(PW):\n",
        "            tmp = np.zeros((PS*PS))\n",
        "            for i in range((PS*PS)):\n",
        "                tmp[i] = dA[n,ch,row,col]/(PS*PS)\n",
        "            dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "    return dP"
      ],
      "metadata": {
        "id": "eJxdQv_8J6eJ"
      },
      "execution_count": 722,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVEmjRcyRW08",
        "outputId": "1dab53ad-c293-4f44-a34d-c907e529fe45"
      },
      "execution_count": 723,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[2 6 8 7 6 4]\n",
            "   [8 4 1 3 6 3]\n",
            "   [1 7 5 3 6 6]\n",
            "   [5 0 3 4 1 0]\n",
            "   [5 4 7 2 3 7]\n",
            "   [5 1 2 1 0 1]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling = AveragePool2D(P=2)\n",
        "A = Pooling.forward(X)\n",
        "print(A.shape)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCrruQwnRfRy",
        "outputId": "a235d6bb-8de2-4fef-92bb-78dc290ecf8a"
      },
      "execution_count": 724,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 3, 3)\n",
            "[[[[5.   4.75 4.75]\n",
            "   [3.25 3.75 3.25]\n",
            "   [3.75 3.   2.75]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling.Pindex"
      ],
      "metadata": {
        "id": "bQqhhUQdRvO0"
      },
      "execution_count": 725,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
        "print(dA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peQAEjEwR0t4",
        "outputId": "f53be177-b902-4f49-86e2-ae303bf310fe"
      },
      "execution_count": 726,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[1 8 5]\n",
            "   [8 6 1]\n",
            "   [3 8 1]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dZ = Pooling.backward(dA)\n",
        "\n",
        "print(dZ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVOTIu_dR-41",
        "outputId": "ee56206c-ed48-4b87-bbff-aff12e25efc4"
      },
      "execution_count": 727,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.25 0.25 2.   2.   1.25 1.25]\n",
            "   [0.25 0.25 2.   2.   1.25 1.25]\n",
            "   [2.   2.   1.5  1.5  0.25 0.25]\n",
            "   [2.   2.   1.5  1.5  0.25 0.25]\n",
            "   [0.75 0.75 2.   2.   0.25 0.25]\n",
            "   [0.75 0.75 2.   2.   0.25 0.25]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Problem 6 - Flatten for smoothing"
      ],
      "metadata": {
        "id": "FqSKQCgyTbPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "  def __ini__(self,):\n",
        "    pass\n",
        "  def forward(self,X):\n",
        "    self.shape = X.shape\n",
        "    return X.reshape(len(X),-1)\n",
        "\n",
        "  def backward(self,X):\n",
        "    return X.reshape(self.shape)  "
      ],
      "metadata": {
        "id": "HiPzYegXSHQA"
      },
      "execution_count": 728,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST = np.zeros([20,2,5,5])\n",
        "flt = Flatten()\n",
        "flat_forward = flt.forward(TEST)\n",
        "print('Forward_shape:', flat_forward.shape)\n",
        "print('Backward_shape:', flt.backward(flat_forward).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JY-OmqADVoX",
        "outputId": "bdbd0819-91f2-4314-ae88-99bb1161e526"
      },
      "execution_count": 729,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward_shape: (20, 50)\n",
            "Backward_shape: (20, 2, 5, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 7 - Training and Estimation "
      ],
      "metadata": {
        "id": "LNrYozjOQ7Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scratch CNN\n",
        "class Scratch2dCNNClassifier():\n",
        "  def __init__(self, NN, CNN, n_epoch=10, n_batch=1, verbose=False):\n",
        "    #parameters\n",
        "    self.n_epoch = n_epoch\n",
        "    self.n_batch = n_batch\n",
        "    self.verbose = verbose\n",
        "    self.log_loss = np.zeros(self.n_epoch)\n",
        "    self.NN = NN\n",
        "    self.CNN = CNN\n",
        "\n",
        "  def loss_function(self,y,yt):\n",
        "    delta = 1e-7\n",
        "    return -np.mean(yt*np.log(y+delta))\n",
        "\n",
        "  def accuracy(self,Z,Y):\n",
        "    return accuracy_score(Y,Z)\n",
        "\n",
        "  def fit(self, X, y, X_val=False, y_val=False):\n",
        "    for epoch in range(self.n_epoch):\n",
        "      #Mini-Batch Processing\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "\n",
        "      self.loss = 0\n",
        "      for mini_X_train, mini_y_train in get_mini_batch:\n",
        "        #Forward Propagation\n",
        "        forward_data = mini_X_train[:,np.newaxis,:,:]\n",
        "\n",
        "        #Conv\n",
        "        for layer in range(len(self.CNN)):\n",
        "          forward_data = self.CNN[layer].forward(forward_data)\n",
        "\n",
        "        #Flatten\n",
        "        flt = Flatten()\n",
        "        forward_data = flt.forward(forward_data)\n",
        "\n",
        "        #NN\n",
        "        for layer in range(len(self.NN)):\n",
        "          forward_data = self.NN[layer].forward(forward_data)\n",
        "\n",
        "        #Predicted Value\n",
        "        Z = forward_data\n",
        "\n",
        "        #Back Propagation\n",
        "        backward_data = (Z - mini_y_train)/self.n_batch\n",
        "        for layer in range(len(self.NN)-1,-1,-1):\n",
        "          backward_data = self.NN[layer].backward(backward_data)\n",
        "\n",
        "        backward_data = flt.backward(backward_data)\n",
        "\n",
        "        for layer in range(len(self.CNN)-1,-1,-1):\n",
        "          backward_data = self.CNN[layer].backward(backward_data)\n",
        "\n",
        "        #Loss function\n",
        "        self.loss += self.loss_function(Z,mini_y_train)\n",
        "      \n",
        "      self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "      self.log_acc[epoch] = self.accuracy(self.predict(X), np.argmax(y, axis=1))\n",
        "    def predict(self, X):\n",
        "      predict_data = X[:,np.newaxis,:,:]\n",
        "\n",
        "      #Conv\n",
        "      for layer in range(len(self.CNN)):\n",
        "        pred_data = flt.forward(pred_data)\n",
        "\n",
        "      flt = Flatten()\n",
        "      pred_data = flt.forward(pred_data)\n",
        "\n",
        "      #NN\n",
        "      for layer in range(len(self.NN)):\n",
        "        pred_data = self.NN[layer].forward(pred_data)\n",
        "\n",
        "      return np.argmax(pred_data, axis=1)"
      ],
      "metadata": {
        "id": "wZK3gSLXEae2"
      },
      "execution_count": 730,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All bounding layers\n",
        "NN = {0:FC(7840, 400,HeInitializer(),AdaGrad(0.01), ReLU()),\n",
        "      1:FC(400, 200,HeInitializer(),AdaGrad(0.01), ReLU()),\n",
        "      2:FC(200, 10,SimpleInitializer(0.01),AdaGrad(0.01), softmax()),}"
      ],
      "metadata": {
        "id": "Mp-RdD38hCfF"
      },
      "execution_count": 731,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convolutional Layer\n",
        "CNN = {0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1,S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU())}"
      ],
      "metadata": {
        "id": "ZWVfDazoiN15"
      },
      "execution_count": 732,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning\n",
        "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=10,n_batch=200,verbose=False)\n",
        "\n",
        "cnn1.fit(X_train[0:1000], y_train[0:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "lWRDx6oEjjIz",
        "outputId": "6ba36373-00ab-46bb-8e6b-31195416f68b"
      },
      "execution_count": 735,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-735-ec6bf6b7b2d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScratch2dCNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-730-c11fb17c6839>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#Conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m           \u001b[0mforward_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#Flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-711-53d66665ee37>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mOH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: output_shape2d() missing 1 required positional argument: 'SW'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimate\n",
        "y_pred = cnn1.predict(X_valid[0:100])\n",
        "\n",
        "#Positive solution rate\n",
        "accuracy = accuracy_score(np.argmax(y_valid[0:100],axis=1, y_pred))\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "2ee1_NRmkLsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise the loss function for each epoch\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig = plt.subplots(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('LOSS')\n",
        "plt.plot(cnn1.log_loss, 'bo--')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('ACC')\n",
        "plt.plot(cnn1.log_acc, 'rs--');"
      ],
      "metadata": {
        "id": "sBWvZfNJCUDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 8 (Advanced Assignment)- LeNet"
      ],
      "metadata": {
        "id": "797BemK8D4Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LeNet structure\n",
        "#Convolutional layers\n",
        "LeNetCNN = {0:SimpleConv2d(F=6, C=1, FH=5, FW=5, P=2,S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU()),\n",
        "       1:MaxPool2D(P=2),\n",
        "       2:SimpleConv2d(F=6, C=1, FH=5, FW=5, P=2,S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU()),\n",
        "       3:MaxPool2D(P=2)}\n",
        "\n",
        "#Fully connected layers\n",
        "LeNetNN = {0:FC(7840, 400,HeInitializer(),AdaGrad(0.01), ReLU()),\n",
        "      1:FC(400, 200,HeInitializer(),AdaGrad(0.01), ReLU()),\n",
        "      2:FC(200, 10,SimpleInitializer(0.01),AdaGrad(0.01), softmax()),}\n",
        "\n",
        "# Learning\n",
        "LeNet = Scratch2dCNNClassifier(NN=LeNetNN,CNN=LeNetCNN,n_epoch=10,n_batch=20,verbose=False)\n",
        "\n",
        "cnn1.fit(X_train[0:1000], y_train[0:1000])"
      ],
      "metadata": {
        "id": "kXTGdHJwEBiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_LeNet = cnn1.predict(X_valid[0:100])\n",
        "\n",
        "#Positive solution rate\n",
        "accuracy = accuracy_score(np.argmax(y_valid[0:100],axis=1, y_pred_LeNet))\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "zw1NmXFVIjQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise the loss function for each epoch\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig = plt.subplots(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('LOSS')\n",
        "plt.plot(LeNet.log_loss, 'bo--')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('ACC')\n",
        "plt.plot(LeNet.log_acc, 'rs--');"
      ],
      "metadata": {
        "id": "FMghlAYRI4Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 9- (Advanced) List of famous CNN structures:\n",
        "\n",
        "\n",
        "* AlexNet(2012\n",
        "* ZFNet(2013)\n",
        "* GoogleNet(2014)\n",
        "* VGGNet(2014)\n",
        "* ResNet(2015)\n",
        "* SENet(2017)\n",
        "\n"
      ],
      "metadata": {
        "id": "GyUbLhTlJRd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 10 - Calculating output size and number of parameters\n",
        "1. \n",
        "* Input size : 144 x 144, 3 channels\n",
        "* Filter size: 3 x 3, 6 channels\n",
        "* Stride : 1\n",
        "* Padding: None\n",
        "* Output size: 6x142x142, Number of parameters: 10416(weight=162, bias=6)\n",
        "2.\n",
        "* Input size : 60x60, 24 channels\n",
        "* Filter size: 3 x 3, 48 channels\n",
        "* Stride : 1\n",
        "* Padding: None\n",
        "* Output size: 48x58x58, Number of parameters: 10416(weight=10368, bias=48)\n",
        "3.\n",
        "* Input size : 20x20, 10 channels\n",
        "* Filter size: 3 x 3, 20 channels\n",
        "* Stride: 2\n",
        "* Padding: None\n",
        "* Output size: 20x9x9, Number of parameters: 1820(weight=1800, bias=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "_GQIN56bKH-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 11- Survey of Filter Size\n",
        "1. Why are 3x3 filters commonly used instead of larger ones such as 7x7?\n",
        "   * This is because the parameters will be huge. The purpose of convolution is to extract features (including positional relationships) between input parameters. Increasing the filter size is going against this reason.\n",
        "2. Whatis the effect of a 1x1 filter with no height or width direction\n",
        "   * The filter doesn't do anything to the image and it remains the same even after the process. "
      ],
      "metadata": {
        "id": "50A8a12dNvMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5XceZMMrKEbs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}