{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 27_Deep Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mochismo/LearnPython/blob/main/Copy_of_27_Deep_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 - Fully Connected Layers "
      ],
      "metadata": {
        "id": "eLTL_n7YjQtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xb23HMPZ4Q2U",
        "outputId": "e7d94043-39ef-4ece-ccd8-85a797ecd5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p0kFuQnhgHvg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "  def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "    self.n_nodes1 = n_nodes1\n",
        "    self.n_nodes2 = n_nodes2\n",
        "    self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "    self.B = initializer.B(self.n_nodes2)\n",
        "    self.optimizer = optimizer\n",
        "    self.HW = 0\n",
        "    self.HB = 0\n",
        "\n",
        "  def forward(self, X):\n",
        "      self.Z = X\n",
        "      self.A = X @ self.W + self.B\n",
        "      return self.A \n",
        "\n",
        "  def backward(self, dA):\n",
        "      self.dB = np.sum(dA, axis=0)\n",
        "      self.dW  = self.Z.T @ dA\n",
        "      self.dZ = dA @ self.W.T\n",
        "      self = self.optimizer.update(self)\n",
        "      return self.dZ    "
      ],
      "metadata": {
        "id": "nuCAz5jZm88k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2"
      ],
      "metadata": {
        "id": "o999ymNCq9jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W = self.sigma* np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B = self.sigma* np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "91ikcRHivG4f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "problem 3 - Optimization Methods"
      ],
      "metadata": {
        "id": "v8i0FP7TwJU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    Stochastic gradient descent\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : Learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr* layer.dW/len(layer.z)\n",
        "      layer.B -= self.lr* layer.dB/len(layer.z)\n",
        "      return layer\n",
        "    \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "uB_cgLY5wSQz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4 - Activation Functions"
      ],
      "metadata": {
        "id": "kVX7oBd_xl4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "  \n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    Z = 1/(1 + np.exp(-self.A))\n",
        "    return Z\n",
        "  def backward(self, dZ):\n",
        "    dA = dZ*((1/(1 + np.exp(-self.A))) - (1/(1 + np.exp(-self.A)))**2)\n",
        "    return dA"
      ],
      "metadata": {
        "id": "unEk_eg5xtQm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "  \n",
        "  def forward(self, A):\n",
        "    Z = np.tanh(self.A)\n",
        "    return Z\n",
        "  def backward(self, dZ):\n",
        "    dA = dz*(1 - np.tanh(self.A)**2)\n",
        "    return dA"
      ],
      "metadata": {
        "id": "bvuBGI491P_m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax:\n",
        "\n",
        "  def forward(self, A):\n",
        "    Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "    return Z\n",
        "  \n",
        "  def backward(self, Z, y):\n",
        "    dA = Z -y \n",
        "    loss = - np.sum(y*np.log(Z)) / len(y)\n",
        "    return dA, loss\n"
      ],
      "metadata": {
        "id": "8iydHnvO2KgY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5 - Creation of the ReLU Class"
      ],
      "metadata": {
        "id": "bk87kvQc67og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "\n",
        "  def forward(self, A): \n",
        "    self.A = A\n",
        "    Z = np.maximum(0, A)\n",
        "    return Z \n",
        "  \n",
        "  def backward(self, dZ):\n",
        "    dA = dZ * np.where(self.A > 0, 1, 0)\n",
        "    return dA "
      ],
      "metadata": {
        "id": "olezBeBT7KOG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6 - Initial value of weight"
      ],
      "metadata": {
        "id": "WUfhZjAl9d3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial value of Xavier"
      ],
      "metadata": {
        "id": "LAKEO0XP-vlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "\n",
        "  def __init__(self, sigma):\n",
        "    _ = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    self.sigma = 1 / np.sqt(n_nodes1)\n",
        "    W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
        "    return W \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    B = self.sigma*np.random.randn(1, n_nodes2)\n",
        "    return B \n"
      ],
      "metadata": {
        "id": "vjnGnqwB93a5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "\n",
        "  def __init__(self, sigma):\n",
        "    _ = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    self.sigma = np.sqrt(2 / n_nodes1)\n",
        "    W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
        "    return W \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    B = self.sigma*np.random.randn(1, n_nodes2)\n",
        "    return B "
      ],
      "metadata": {
        "id": "VcurYrE-BFL-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 7 - Optimization Method"
      ],
      "metadata": {
        "id": "YQCIADpzCKH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr \n",
        "\n",
        "  def update(self, layer):\n",
        "    layer.HW += layer.dW * layer.dW\n",
        "    layer.HB += layer.dB * layer.dB\n",
        "    delta = 1e-7\n",
        "    layer.W -=self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
        "    layer.B -=self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
        "    return layer "
      ],
      "metadata": {
        "id": "l5DsMeljCl9w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 8 - Class Completion\n",
        "\n",
        "Let's complete the ScratchDeepNeuralNetrwokClassifier class that can be trained and estimated with any configuration. "
      ],
      "metadata": {
        "id": "5lOJCHQCEjv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "  def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "    self.batch_size = batch_size\n",
        "    np.random.seed(seed)\n",
        "    shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "    self._X = X[shuffle_index]\n",
        "    self._y = y[shuffle_index]\n",
        "    self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._stop\n",
        "\n",
        "  def __getitem__(self, item): \n",
        "    p0 = item*self.batch_size\n",
        "    p1 = item*self.batch_size + self.batch_size\n",
        "    return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "  def __iter__(self): \n",
        "    self._counter = 0\n",
        "    return self \n",
        "\n",
        "  def __next__(self):\n",
        "    if self._counter >= self._stop:\n",
        "      raise StopIteration()\n",
        "    p0 = self._counter*self.batch_size\n",
        "    p1 = self._counter*self.batch_size + self.batch_size \n",
        "    self._counter += 1\n",
        "    return self._X[p0:p1], self._y[p0:p1] \n"
      ],
      "metadata": {
        "id": "tdY6SXGfGc_h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "  def __init__(self, verbose=False, epoch=1, optimizer= SGD, initializer = HeInitializer, activater = ReLU):\n",
        "    self.verbose = verbose\n",
        "    self.batch_size = 20 \n",
        "    self.n_features = 784\n",
        "    self.n_nodes1 = 400\n",
        "    self.n_nodes2 = 400\n",
        "    self.n_output = 10\n",
        "    self.sigma = 0.02\n",
        "    self.lr = 0.5 \n",
        "    self.epoch = epoch\n",
        "    self.optimizer = optimizer\n",
        "    self.initializer = initializer\n",
        "    self.activater = activater\n",
        "\n",
        "  def fit(self, X, y, X_val = None, y_val = None):\n",
        "    self.loss_train = []\n",
        "    self.loss_val = []\n",
        "    optimizer = self.optimizer(self.lr)\n",
        "    self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "    self.activation1 = self.activater()\n",
        "    self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "    self.activation2 = self.activater()\n",
        "    self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "    self.activation3 = softmax()\n",
        "\n",
        "    for i in range(self.epoch):\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "      for mini_X, mini_y in get_mini_batch:\n",
        "        A1 = self.FC1.forward(mini_X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        # print(Z2.shape)\n",
        "\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        dA3, loss = self.activation3.backward(Z3, mini_y)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC2.backward(dA1)\n",
        "\n",
        "      if self.verbose:\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        self.loss_train.append(self.activation3.backward(Z3, y)[1])\n",
        "\n",
        "        if X_val is not None:\n",
        "          A1 = self.FC1.forward(X_val)\n",
        "          Z1 = self.activation1.forward(A1)\n",
        "          A2 = self.FC2.forward(Z1)\n",
        "          Z2 = self.activation2.forward(A2)\n",
        "          A3 = self.FC3.forward(Z2)\n",
        "          Z3 = self.activation3.forward(A3)\n",
        "          self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
        "\n",
        "  def predict(self, X):\n",
        "    A1 = self.FC1.forward(X)\n",
        "    Z1 = self.activation1.forward(A1)\n",
        "    A2 = self.FC2.forward(Z1)\n",
        "    Z2 = self.activation2.forward(A2)\n",
        "    A3 = self.FC3.forward(Z2)\n",
        "    Z3 = self.activation3.forward(A3)\n",
        "    return np.argmax(Z3, axis=1)\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "axE4PA5nMEVJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 9 - Learning Estimation\n",
        "\n",
        "Let's create several networks with varying numbers of layers and activation functions."
      ],
      "metadata": {
        "id": "IyOGs0EmtFyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "-yiHJsyFumEy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "mlb_VpVKvoq9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis]) "
      ],
      "metadata": {
        "id": "1-9EwM1TwaI1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN = ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) "
      ],
      "metadata": {
        "id": "HMMhZiQaxrpK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = SDNN.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuKNDskEy-Ib",
        "outputId": "33cba75a-9f66-44af-be8d-44de3b3634f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9520833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN.epoch+1)));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NANLHt_xz2r3",
        "outputId": "97c758ac-0826-4247-8024-c0e5ef486b3b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the accuracy with other layers, (4 and 6 layers)"
      ],
      "metadata": {
        "id": "-xSu2yiu1Iw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_4():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20 \n",
        "        self.n_features = 784 \n",
        "        self.n_nodes1 = 400 \n",
        "        self.n_nodes2 = 200 \n",
        "        self.n_nodes3 = 150 \n",
        "        self.n_output = 10 \n",
        "        self.sigma = 0.02 \n",
        "        self.lr = 0.5 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = self.activater()\n",
        "        self.FC4 = FC(self.n_nodes3, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation4 = softmax()\n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                self.forward(mini_X)\n",
        "                self.backward(mini_y)\n",
        "            \n",
        "            if self.verbose:\n",
        "                self.forward(X)\n",
        "                self.loss_train.append(self.activation4.backward(self.Z4, y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    self.forward(X_val)\n",
        "                    self.loss_val.append(self.activation4.backward(self.Z4, y_val)[1])\n",
        "    \n",
        "    def forward(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        A4 = self.FC4.forward(Z3)\n",
        "        self.Z4 = self.activation4.forward(A4)\n",
        "        \n",
        "    def backward(self, y):\n",
        "        dA4, self.loss = self.activation4.backward(self.Z4, y) \n",
        "        dZ3 = self.FC4.backward(dA4)\n",
        "        dA3 = self.activation3.backward(dZ3)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC1.backward(dA1) \n",
        "        \n",
        "    def predict(self, X):\n",
        "        self.forward(X)\n",
        "        return np.argmax(self.Z4, axis=1) "
      ],
      "metadata": {
        "id": "4MkjSV7f1k-Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN4 = ScratchDeepNeuralNetrowkClassifier_4(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN4.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN4.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "qug_HldWKtjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN4.epoch+1)));"
      ],
      "metadata": {
        "id": "TBiPWOOJLdki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_6():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20 \n",
        "        self.n_features = 784 \n",
        "        self.n_nodes1 = 400 \n",
        "        self.n_nodes2 = 200 \n",
        "        self.n_nodes3 = 150 \n",
        "        self.n_nodes4 = 100 \n",
        "        self.n_nodes5 = 50 \n",
        "        self.n_output = 10 \n",
        "        self.sigma = 0.02 \n",
        "        self.lr = 0.5 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = self.activater()\n",
        "        self.FC4 = FC(self.n_nodes3, self.n_nodes4, self.initializer(self.sigma), optimizer)\n",
        "        self.activation4 = self.activater()\n",
        "        self.FC5 = FC(self.n_nodes4, self.n_nodes5, self.initializer(self.sigma), optimizer)\n",
        "        self.activation5 = self.activater()\n",
        "        self.FC6 = FC(self.n_nodes5, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation6 = softmax()\n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                self.forward(mini_X)\n",
        "                self.backward(mini_y)\n",
        "            \n",
        "            if self.verbose:\n",
        "                self.forward(X)\n",
        "                self.loss_train.append(self.activation6.backward(self.Z6, y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    self.forward(X_val)\n",
        "                    self.loss_val.append(self.activation6.backward(self.Z6, y_val)[1])\n",
        "    \n",
        "    def forward(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        A4 = self.FC4.forward(Z3)\n",
        "        Z4 = self.activation4.forward(A4)\n",
        "        A5 = self.FC5.forward(Z4)\n",
        "        Z5 = self.activation5.forward(A5)\n",
        "        A6 = self.FC6.forward(Z5)\n",
        "        self.Z6 = self.activation6.forward(A6)\n",
        "        \n",
        "    def backward(self, y):\n",
        "        dA6, self.loss = self.activation6.backward(self.Z6, y) \n",
        "        dZ5 = self.FC6.backward(dA6)\n",
        "        dA5 = self.activation5.backward(dZ5)\n",
        "        dZ4 = self.FC5.backward(dA5)\n",
        "        dA4 = self.activation4.backward(dZ4)\n",
        "        dZ3 = self.FC4.backward(dA4)\n",
        "        dA3 = self.activation3.backward(dZ3)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC1.backward(dA1) \n",
        "        \n",
        "    def predict(self, X):\n",
        "        self.forward(X)\n",
        "        return np.argmax(self.Z6, axis=1)  "
      ],
      "metadata": {
        "id": "5jVnvbbsL2li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN6 = ScratchDeepNeuralNetrowkClassifier_6(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN6.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN6.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "j-2TcxwwTS-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN6.epoch+1)));"
      ],
      "metadata": {
        "id": "DLpO-FRQTr9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, we can say that the accuracy was at its best when we had three layers. \n",
        "\n",
        "Let's finally generalize the ScratchDeepNeuralNetrwokClassifier and make it possible to input layers with the number of nodes. "
      ],
      "metadata": {
        "id": "zhdNIJaxUGKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class General_ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU, n_nodes=None):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20 \n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "        self.n_nodes = n_nodes \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = [] \n",
        "        optimizer = self.optimizer(self.lr)\n",
        "        self.fcs = [] \n",
        "        self.act = [] \n",
        "        \n",
        "        for i in range(len(self.n_nodes)-2):\n",
        "            self.fcs.append(FC(self.n_nodes[i], self.n_nodes[i+1], self.initializer(self.sigma), optimizer))\n",
        "            self.act.append(self.activater())\n",
        "        self.fcs.append(FC(self.n_nodes[i+1], self.n_nodes[-1], self.initializer(self.sigma), optimizer))\n",
        "        self.act.append(softmax())\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                A = []\n",
        "                Z = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                    if i == 0:\n",
        "                        A.append(f.forward(mini_X))\n",
        "                        Z.append(a.forward(A[i]))\n",
        "                    else:\n",
        "                        A.append(f.forward(Z[i-1]))\n",
        "                        Z.append(a.forward(A[i]))     \n",
        "                dA = []\n",
        "                dZ = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs[::-1], self.act[::-1])):\n",
        "                    if i == 0:\n",
        "                        dA.append(a.backward(Z[-(i+1)], mini_y)[0])\n",
        "                        dZ.append(f.backward(dA[i]))\n",
        "                    else:\n",
        "                        dA.append(a.backward(dZ[i-1]))\n",
        "                        dZ.append(f.backward(dA[i]))\n",
        "\n",
        "            if self.verbose:\n",
        "                A = []\n",
        "                Z = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                    if i == 0:\n",
        "                        A.append(f.forward(X))\n",
        "                        Z.append(a.forward(A[i]))\n",
        "                    else:\n",
        "                        A.append(f.forward(Z[i-1]))\n",
        "                        Z.append(a.forward(A[i]))           \n",
        "                self.loss_train.append(self.act[-1].backward(Z[-1], y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    A = []\n",
        "                    Z = []\n",
        "                    for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                        if i == 0:\n",
        "                            A.append(f.forward(X_val))\n",
        "                            Z.append(a.forward(A[i]))\n",
        "                        else:\n",
        "                            A.append(f.forward(Z[i-1]))\n",
        "                            Z.append(a.forward(A[i]))           \n",
        "                    self.loss_val.append(self.act[-1].backward(Z[-1], y_val)[1])\n",
        "    \n",
        "    def predict(self, X):\n",
        "        A = []\n",
        "        Z = []\n",
        "        for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "            if i == 0:\n",
        "                A.append(f.forward(X))\n",
        "                Z.append(a.forward(A[i]))\n",
        "            else:\n",
        "                A.append(f.forward(Z[i-1]))\n",
        "                Z.append(a.forward(A[i]))\n",
        "        return np.argmax(Z[-1], axis=1)"
      ],
      "metadata": {
        "id": "QOXKxpH2VUcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it with five layers"
      ],
      "metadata": {
        "id": "et0z6NVGgrd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_list = [784, 400, 200, 150, 100, 10]\n",
        "SDNN5 = General_ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU, n_nodes=node_list)\n",
        "SDNN5.fit(X_train, y_train_one_hot, X_val, y_test_one_hot)\n",
        "pred = SDNN5.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "YegKsBGLgxN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN5.epoch+1)), SDNN5.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN5.epoch+1)), SDNN5.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN5.epoch+1)));"
      ],
      "metadata": {
        "id": "otTDcKhDh8-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}