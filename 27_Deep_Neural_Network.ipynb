{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "27_Deep Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VI1puzoHDKzS95bwjtR_xVpgiYFe5S37",
      "authorship_tag": "ABX9TyPXYxoxb/MZtLUAD2icqO6S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mochismo/LearnPython/blob/main/27_Deep_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 - Fully Connected Layers "
      ],
      "metadata": {
        "id": "eLTL_n7YjQtq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p0kFuQnhgHvg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "  def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "    self.n_nodes1 = n_nodes1\n",
        "    self.n_nodes2 = n_nodes2\n",
        "    self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "    self.B = initializer.B(self.n_nodes2)\n",
        "    self.optimizer = optimizer\n",
        "    self.HW = 0\n",
        "    self.HB = 0\n",
        "\n",
        "  def forward(self, X):\n",
        "      self.Z = X\n",
        "      self.A = X @ self.W + self.B\n",
        "      return self.A \n",
        "\n",
        "  def backward(self, dA):\n",
        "      self.dB = np.sum(dA, axis=0)\n",
        "      self.dW  = self.Z.T @ dA\n",
        "      self.dZ = dA @ self.W.T\n",
        "      self = self.optimizer.update(self)\n",
        "      return self.dZ    "
      ],
      "metadata": {
        "id": "nuCAz5jZm88k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2"
      ],
      "metadata": {
        "id": "o999ymNCq9jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W = self.sigma* np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B = self.sigma* np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "91ikcRHivG4f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "problem 3 - Optimization Methods"
      ],
      "metadata": {
        "id": "v8i0FP7TwJU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    Stochastic gradient descent\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : Learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr* layer.dW/len(layer.z)\n",
        "      layer.B -= self.lr* layer.dB/len(layer.z)\n",
        "      return layer\n",
        "    \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "uB_cgLY5wSQz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4 - Activation Functions"
      ],
      "metadata": {
        "id": "kVX7oBd_xl4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "  \n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    Z = 1/(1 + np.exp(-self.A))\n",
        "    return Z\n",
        "  def backward(self, dZ):\n",
        "    dA = dZ*((1/(1 + np.exp(-self.A))) - (1/(1 + np.exp(-self.A)))**2)\n",
        "    return dA"
      ],
      "metadata": {
        "id": "unEk_eg5xtQm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "  \n",
        "  def forward(self, A):\n",
        "    Z = np.tanh(self.A)\n",
        "    return Z\n",
        "  def backward(self, dZ):\n",
        "    dA = dz*(1 - np.tanh(self.A)**2)\n",
        "    return dA"
      ],
      "metadata": {
        "id": "bvuBGI491P_m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax:\n",
        "\n",
        "  def forward(self, A):\n",
        "    Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "    return Z\n",
        "  \n",
        "  def backward(self, Z, y):\n",
        "    dA = Z -y \n",
        "    loss = - np.sum(y*np.log(Z)) / len(y)\n",
        "    return dA, loss\n"
      ],
      "metadata": {
        "id": "8iydHnvO2KgY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5 - Creation of the ReLU Class"
      ],
      "metadata": {
        "id": "bk87kvQc67og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "\n",
        "  def forward(self, A): \n",
        "    self.A = A\n",
        "    Z = np.maximum(0, A)\n",
        "    return Z \n",
        "  \n",
        "  def backward(self, dZ):\n",
        "    dA = dZ * np.where(self.A > 0, 1, 0)\n",
        "    return dA "
      ],
      "metadata": {
        "id": "olezBeBT7KOG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6 - Initial value of weight"
      ],
      "metadata": {
        "id": "WUfhZjAl9d3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial value of Xavier"
      ],
      "metadata": {
        "id": "LAKEO0XP-vlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "\n",
        "  def __init__(self, sigma):\n",
        "    _ = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    self.sigma = 1 / np.sqt(n_nodes1)\n",
        "    W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
        "    return W \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    B = self.sigma*np.random.randn(1, n_nodes2)\n",
        "    return B \n"
      ],
      "metadata": {
        "id": "vjnGnqwB93a5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "\n",
        "  def __init__(self, sigma):\n",
        "    _ = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    self.sigma = np.sqrt(2 / n_nodes1)\n",
        "    W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
        "    return W \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    B = self.sigma*np.random.randn(1, n_nodes2)\n",
        "    return B "
      ],
      "metadata": {
        "id": "VcurYrE-BFL-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 7 - Optimization Method"
      ],
      "metadata": {
        "id": "YQCIADpzCKH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr \n",
        "\n",
        "  def update(self, layer):\n",
        "    layer.HW += layer.dW * layer.dW\n",
        "    layer.HB += layer.dB * layer.dB\n",
        "    delta = 1e-7\n",
        "    layer.W -=self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
        "    layer.B -=self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
        "    return layer "
      ],
      "metadata": {
        "id": "l5DsMeljCl9w"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 8 - Class Completion\n",
        "\n",
        "Let's complete the ScratchDeepNeuralNetrwokClassifier class that can be trained and estimated with any configuration. "
      ],
      "metadata": {
        "id": "5lOJCHQCEjv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "  def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "    self.batch_size = batch_size\n",
        "    np.random.seed(seed)\n",
        "    shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "    self._X = X[shuffle_index]\n",
        "    self._y = y[shuffle_index]\n",
        "    self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._stop\n",
        "\n",
        "  def __getitem__(self, item): \n",
        "    p0 = item*self.batch_size\n",
        "    p1 = item*self.batch_size + self.batch_size\n",
        "    return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "  def __iter__(self): \n",
        "    self._counter = 0\n",
        "    return self \n",
        "\n",
        "  def __next__(self):\n",
        "    if self._counter >= self._stop:\n",
        "      raise StopIteration()\n",
        "    p0 = self._counter*self.batch_size\n",
        "    p1 = self._counter*self.batch_size + self.batch_size \n",
        "    self._counter += 1\n",
        "    return self._X[p0:p1], self._y[p0:p1] \n"
      ],
      "metadata": {
        "id": "tdY6SXGfGc_h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "  def __init__(self, verbose=False, epoch=1, optimizer= SGD, initializer = HeInitializer, activater = ReLU):\n",
        "    self.verbose = verbose\n",
        "    self.batch_size = 20 \n",
        "    self.n_features = 784\n",
        "    self.n_nodes1 = 400\n",
        "    self.n_nodes2 = 400\n",
        "    self.n_output = 10\n",
        "    self.sigma = 0.02\n",
        "    self.lr = 0.5 \n",
        "    self.epoch = epoch\n",
        "    self.optimizer = optimizer\n",
        "    self.initializer = initializer\n",
        "    self.activater = activater\n",
        "\n",
        "  def fit(self, X, y, X_val = None, y_val = None):\n",
        "    self.loss_train = []\n",
        "    self.loss_val = []\n",
        "    optimizer = self.optimizer(self.lr)\n",
        "    self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "    self.activation1 = self.activater()\n",
        "    self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "    self.activation2 = self.activater()\n",
        "    self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "    self.activation3 = softmax()\n",
        "\n",
        "    for i in range(self.epoch):\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "      for mini_X, mini_y in get_mini_batch:\n",
        "        A1 = self.FC1.forward(mini_X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        # print(Z2.shape)\n",
        "\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        dA3, loss = self.activation3.backward(Z3, mini_y)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC2.backward(dA1)\n",
        "\n",
        "      if self.verbose:\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        self.loss_train.append(self.activation3.backward(Z3, y)[1])\n",
        "\n",
        "        if X_val is not None:\n",
        "          A1 = self.FC1.forward(X_val)\n",
        "          Z1 = self.activation1.forward(A1)\n",
        "          A2 = self.FC2.forward(Z1)\n",
        "          Z2 = self.activation2.forward(A2)\n",
        "          A3 = self.FC3.forward(Z2)\n",
        "          Z3 = self.activation3.forward(A3)\n",
        "          self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
        "\n",
        "  def predict(self, X):\n",
        "    A1 = self.FC1.forward(X)\n",
        "    Z1 = self.activation1.forward(A1)\n",
        "    A2 = self.FC2.forward(Z1)\n",
        "    Z2 = self.activation2.forward(A2)\n",
        "    A3 = self.FC3.forward(Z2)\n",
        "    Z3 = self.activation3.forward(A3)\n",
        "    return np.argmax(Z3, axis=1)\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "axE4PA5nMEVJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 9 - Learning Estimation\n",
        "\n",
        "Let's create several networks with varying numbers of layers and activation functions."
      ],
      "metadata": {
        "id": "IyOGs0EmtFyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "-yiHJsyFumEy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "mlb_VpVKvoq9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis]) "
      ],
      "metadata": {
        "id": "1-9EwM1TwaI1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN = ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) "
      ],
      "metadata": {
        "id": "HMMhZiQaxrpK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = SDNN.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuKNDskEy-Ib",
        "outputId": "4a12ed68-3348-4491-c71a-c5292d0cdaa5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9505833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN.epoch+1)));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NANLHt_xz2r3",
        "outputId": "b3db1039-2790-4a71-cadb-f15cde53ebd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the accuracy with other layers, (4 and 6 layers)"
      ],
      "metadata": {
        "id": "-xSu2yiu1Iw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_4():\n",
        "\n",
        "  def __init__(self, verbose=False, epoch=1, optimizer= SGD, initializer = HeInitializer, activater = ReLU):\n",
        "     self.verbose = verbose\n",
        "     self.batch_size = 20\n",
        "     self.n_features = 784\n",
        "     self.n_nodes1 = 200\n",
        "     self.n_nodes2 = 200\n",
        "     self.n_nodes3 = 200\n",
        "     self.n_output = 10\n",
        "     self.sigma = 0.02\n",
        "     self.lr = 0.5\n",
        "     self.epoch = epoch\n",
        "     self.optimizer = optimizer\n",
        "     self.initializer = initializer\n",
        "     self.activater = activater\n",
        "\n",
        "  def fit(self, X, y, X_val=None, y_val=None):\n",
        "    self.loss_train = []\n",
        "    self.loss_val = []\n",
        "    optimizer = self.optimizer(self.lr)\n",
        "\n",
        "    self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "    self.activation1 = self.activater()\n",
        "    self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "    self.activation2 = self.activater()\n",
        "    self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "    self.activation3 = self.activater()\n",
        "    self.FC4 = FC(self.n_nodes3, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "    self.activation4 = softmax()\n",
        "\n",
        "    for i in range(self.epoch):\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "      for mini_X, mini_y in get_mini_batch:\n",
        "        self.forward(mini_X)\n",
        "        self.backward(mini_y)\n",
        "\n",
        "        if self.verbose:\n",
        "          self.forward(X)\n",
        "          self.loss_train.append(self.activation4.backward(self.Z4, y)[1])\n",
        "\n",
        "        if X_val is not None:\n",
        "          self.forward(X_val)\n",
        "          self.loss_val.append(self.activation4.backward(self.Z4, y_val)[1])\n",
        "\n",
        "  def forward(self, X):\n",
        "    A1 = self.FC1.forward(X)\n",
        "    Z1 = self.activation1.forward(A1)    \n",
        "    A2 = self.FC2.forward(Z1)\n",
        "    Z2 = self.activation2.forward(A2) \n",
        "    A3 = self.FC3.forward(Z2)\n",
        "    Z3 = self.activation3.forward(A3)       \n",
        "    A4 = self.FC4.forward(Z3)\n",
        "    self.Z4 = self.activation4.forward(A4)\n",
        "\n",
        "  def backward(self, y):\n",
        "    dA4, self.loss = self.activation4.backward(self.Z4, y)\n",
        "    dZ3 = self.FC4.backward(dA4) \n",
        "    dA3 = self.activation3.backward(dZ3)\n",
        "    dZ2 = self.FC3.backward(dA3) \n",
        "    dA2 = self.activation2.backward(dZ2)\n",
        "    dZ1 = self.FC2.backward(dA2) \n",
        "    dA1 = self.activation1.backward(dZ1)\n",
        "    dZ0 = self.FC1.backward(dA1) \n",
        "\n",
        "  def predict(self, X):\n",
        "    self.forward(X)\n",
        "    return np.argmax(self.Z4, axis=1)"
      ],
      "metadata": {
        "id": "4MkjSV7f1k-Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN4 = ScratchDeepNeuralNetrowkClassifier_4(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN4.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN4.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "qug_HldWKtjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN4.epoch+1)));"
      ],
      "metadata": {
        "id": "TBiPWOOJLdki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_6():\n",
        "\n",
        "  def __init__(self, verbose=False, epoch=1, optimizer= SGD, initializer = HeInitializer, activater = ReLU):\n",
        "     self.verbose = verbose\n",
        "     self.batch_size = 20\n",
        "     self.n_features = 784\n",
        "     self.n_nodes1 = 400\n",
        "     self.n_nodes2 = 200\n",
        "     self.n_nodes3 = 150\n",
        "     self.n_nodes4 = 100\n",
        "     self.n_nodes5 = 50\n",
        "     self.n_output = 10\n",
        "     self.sigma = 0.02\n",
        "     self.lr = 0.5\n",
        "     self.epoch = epoch\n",
        "     self.optimizer = optimizer\n",
        "     self.initializer = initializer\n",
        "     self.activater = activater\n",
        "\n",
        "  def fit(self, X, y, X_val=None, y_val=None):\n",
        "    self.loss_train = []\n",
        "    self.loss_val = []\n",
        "    optimizer = self.optimizer(self.lr)\n",
        "\n",
        "    self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "    self.activation1 = self.activater()\n",
        "    self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "    self.activation2 = self.activater()\n",
        "    self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "    self.activation3 = self.activater()\n",
        "    self.FC4 = FC(self.n_nodes3, self.n_nodes4, self.initializer(self.sigma), optimizer)\n",
        "    self.activation4 = self.activater()\n",
        "    self.FC5 = FC(self.n_nodes4, self.n_nodes5, self.initializer(self.sigma), optimizer)\n",
        "    self.activation5 = self.activater()\n",
        "    self.FC6 = FC(self.n_nodes5, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "    self.activation6 = softmax()\n",
        "\n",
        "    for in range(self.epoch):\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "      for mini_X, mini_y in get_mini_batch:\n",
        "        self.forward(mini_X)\n",
        "        self.backward(mini_y)\n",
        "\n",
        "        if self.verbose:\n",
        "          self.forward(X)\n",
        "          self.loss_train.append(self.activation4.backward(self.Z6, y)[1])\n",
        "\n",
        "        if X_val is not None:\n",
        "          self.forward(X_val)\n",
        "          self.loss_val.append(self.activation4.backward(self.Z6, y_val)[1])\n",
        "\n",
        "  def forward(self, X):\n",
        "    A1 = self.FC1.forward(X)\n",
        "    Z1 = self.activation1.forward(A1)    \n",
        "    A2 = self.FC2.forward(Z1)\n",
        "    Z2 = self.activation2.forward(A2) \n",
        "    A3 = self.FC3.forward(Z2)\n",
        "    Z3 = self.activation3.forward(A3) \n",
        "    A4 = self.FC4.forward(Z3)\n",
        "    Z4 = self.activation4.forward(A4) \n",
        "    A5 = self.FC5.forward(Z4)\n",
        "    Z5 = self.activation5.forward(A5)             \n",
        "    A6 = self.FC6.forward(Z5)\n",
        "    self.Z6 = self.activation6.forward(A6)\n",
        "\n",
        "  def backward(self, y):\n",
        "    dA6, self.loss = self.activation6.backward(self.Z6, y)\n",
        "    dZ5 = self.FC6.backward(dA6) \n",
        "    dA5 = self.activation5.backward(dZ5)\n",
        "    dZ4 = self.FC5.backward(dA5) \n",
        "    dA4 = self.activation4.backward(dZ4)\n",
        "    dZ3 = self.FC4.backward(dA4) \n",
        "    dA3 = self.activation3.backward(dZ3)\n",
        "    dZ2 = self.FC3.backward(dA3) \n",
        "    dA2 = self.activation2.backward(dZ2)\n",
        "    dZ1 = self.FC2.backward(dA2) \n",
        "    dA1 = self.activation1.backward(dZ1)\n",
        "    dZ0 = self.FC1.backward(dA1) \n",
        "\n",
        "  def predict(self, X):\n",
        "    self.forward(X)\n",
        "    return np.argmax(self.Z6, axis=1)\n"
      ],
      "metadata": {
        "id": "5jVnvbbsL2li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN6 = ScratchDeepNeuralNetrowkClassifier_6(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN6.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN6.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "j-2TcxwwTS-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN6.epoch+1)));"
      ],
      "metadata": {
        "id": "DLpO-FRQTr9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, we can say that the accuracy was at its best when we had three layers. \n",
        "\n",
        "Let's finally generalize the ScratchDeepNeuralNetrwokClassifier and make it possible to input layers with the number of nodes. "
      ],
      "metadata": {
        "id": "zhdNIJaxUGKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class General_ScratchDeepNeuralNetrowkClassifier():\n",
        "  \n",
        "  def __init__(self, verbose=False, epoch=1, optimizer= SGD, initializer = HeInitializer, activater = ReLU, n_nodes=None):\n",
        "    self.verbose = verbose\n",
        "    self.batch_size = 20\n",
        "    self.sigma = 0.02\n",
        "    self.lr = 0.5\n",
        "    self.epoch = epoch\n",
        "    self.optimizer = optimizer\n",
        "    self.initializer = initializer\n",
        "    self.activater = activater\n",
        "    self.n_nodes = n_nodes\n",
        "\n",
        "  def fit(self, X, y, X_val=None, y_val=None):\n",
        "    self.loss_train = []\n",
        "    self.loss_val = []\n",
        "    optimizer = self.optimizer(self.lr)\n",
        "    self.fcs = []\n",
        "    self.act = []\n",
        "\n",
        "    for i in range(len(self.n_nodes)-2):\n",
        "      self.fcs.append(FC(self.n_nodes[i], self.n_nodes[i+1], self.initializer(self.sigma), optimizer))\n",
        "      self.act.append(self.activater())\n",
        "    self.fcs.append(FC(self.n_nodes[i], self.n_nodes[-1], self.initializer(self.sigma), optimizer))\n",
        "    self.act.append(softmax)\n",
        "\n",
        "    for i in range(self.epoch):\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "      for mini_X, mini_y in get_mini_batch:\n",
        "        A = []\n",
        "        Z = []\n",
        "        for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "          if i == 0:\n",
        "            A.append(f.forward(mini_X))  \n",
        "            Z.append(a.forward(A[i]))\n",
        "          else:\n",
        "            A.append(f.forward(Z[i-1]))   \n",
        "            Z.append(a.forward(A[i]))\n",
        "\n",
        "        dA = []\n",
        "        dZ = []\n",
        "        for i, (f, a) in enumerate(zip(self.fcs[::-1], self.act[::-1])):\n",
        "          if i == 0:\n",
        "            dA.append(a.backward(Z[-(i+1)], mini_y)[0])  \n",
        "            dZ.append(f.backward(dA[i]))\n",
        "          else:\n",
        "            dA.append(a.backward(dZ[i-1]))   \n",
        "            dZ.append(f.backward(dA[i])) \n",
        "\n",
        "        if self.verbose:\n",
        "          A = [] \n",
        "          Z = []\n",
        "          for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "            if i == 0:\n",
        "              A.append(f.forward(X))\n",
        "              Z.append(a.forward(A[i]))\n",
        "            else:\n",
        "              A.append(f.forward(Z[i-1]))   \n",
        "              Z.append(a.forward(A[i]))\n",
        "          self.loss_train.append(self.act[-1].backward(Z[-1], y)[1])\n",
        "\n",
        "          if X_val is not None:\n",
        "            A = []\n",
        "            Z = []\n",
        "            for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "            if i == 0:\n",
        "              A.append(f.forward(X_val))\n",
        "              Z.append(a.forward(A[i]))\n",
        "            else:\n",
        "              A.append(f.forward(Z[i-1]))   \n",
        "              Z.append(a.forward(A[i]))\n",
        "          self.loss_val.append(self.act[-1].backward(Z[-1], y_val)[1])\n",
        "\n",
        "  def predict(self, X):\n",
        "    A = []\n",
        "    Z = []\n",
        "    for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "      if i == 0:\n",
        "        A.append(f.forward(X))\n",
        "        Z.append(a.forward(A[i]))\n",
        "      else:\n",
        "        A.append(f.forward(Z[i-1]))   \n",
        "        Z.append(a.forward(A[i]))\n",
        "    return np.argmax(Z[-1], axis=1)\n",
        "  \n",
        "    \n"
      ],
      "metadata": {
        "id": "QOXKxpH2VUcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it with five layers"
      ],
      "metadata": {
        "id": "et0z6NVGgrd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_list = [784, 400, 200, 150, 100, 10]\n",
        "SDNN5 = General_ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU, n_nodes=None)\n",
        "\n",
        "SDNN5.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN5.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "YegKsBGLgxN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN5.epoch+1)), SDNN5.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN5.epoch+1)), SDNN5.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN5.epoch+1)));"
      ],
      "metadata": {
        "id": "otTDcKhDh8-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}